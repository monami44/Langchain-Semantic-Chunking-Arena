The term "interpretability" is oftenly used by machine learning researchers
each with their own intuitive understanding of it. There is no universal well
agreed upon definition of interpretability in machine learning. As any type of
science discipline is mainly driven by the set of formulated questions rather
than by different tools in that discipline, e.g. astrophysics is the discipline
that learns the composition of stars, not as the discipline that use the
spectroscopes. Similarly, we propose that machine learning interpretability
should be a discipline that answers specific questions related to
interpretability. These questions can be of statistical, causal and
counterfactual nature. Therefore, there is a need to look into the
interpretability problem of machine learning in the context of questions that
need to be addressed rather than different tools. We discuss about a
hypothetical interpretability framework driven by a question based scientific
approach rather than some specific machine learning model. Using a question
based notion of interpretability, we can step towards understanding the science
of machine learning rather than its engineering. This notion will also help us
understanding any specific problem more in depth rather than relying solely on
machine learning methods.