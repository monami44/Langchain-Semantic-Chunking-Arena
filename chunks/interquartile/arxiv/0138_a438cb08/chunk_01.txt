As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or nondiscrimination. However, despite the interest in interpretability, there is very little consensus on what interpretable machine learning is and how it should be measured.